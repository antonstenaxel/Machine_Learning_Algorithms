{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load csv file as np.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    with open('pima-indians-diabetes.csv') as f: \n",
    "        raw_data = np.array([line.split(\",\")[:-1] for line in f])\n",
    "        columns = raw_data[0]\n",
    "        data = raw_data[1:]\n",
    "    return columns,data.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split dataset according to holdout validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_train_split(data,fraction):\n",
    "    n_entries = len(data)\n",
    "    n_train = int(fraction*n_entries)\n",
    "    \n",
    "    indicies = np.random.permutation(np.arange(n_entries))\n",
    "\n",
    "    train_set = data[indicies[:n_train]]\n",
    "    test_set = data[indicies[n_train:]]\n",
    "    \n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NaiveBayesPredictor():\n",
    "    \n",
    "    def __init__(self,data):\n",
    "        self.data = data\n",
    "        self.prior = calculate_prior()\n",
    "        self.calculate_mean_and_std()\n",
    "        \n",
    "    def calculate_prior(self):\n",
    "        n_datapoints = len(self.data)\n",
    "        n_class_0 = len(self.data[self.data[:,-1] == 0])\n",
    "        \n",
    "        return np.array([n_class_0 n_datapoints-n_class_1])/n_datapoints\n",
    "        \n",
    "        \n",
    "    def predict(self,values):\n",
    "        return self.calc_probabilities(values)\n",
    "    \n",
    "    def calculate_mean_and_std(self):\n",
    "        class_0 = self.data[self.data[:,-1] == 0]\n",
    "        class_1 = self.data[self.data[:,-1] == 1]\n",
    "    \n",
    "        self.mean = [np.mean(class_0, axis=0)[:-1], np.mean(class_1, axis=0)[:-1]]\n",
    "        self.std = [np.std(class_0, axis=0)[:-1], np.std(class_1, axis=0)[:-1]] \n",
    "    \n",
    "    def calc_probabilities(self,x):\n",
    "        \n",
    "        exponent = np.exp( -np.power(x-self.mean[0],2) / np.power(2*self.std[0],2) )\n",
    "        return (1 / (math.sqrt(2*math.pi) * self.std[0])) * exponent\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = NaiveBayesPredictor(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = test_set[1,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.12687577,  2.4844413 ,  2.48655408,  2.62563089,  3.35158092,\n",
       "        3.38730505,  2.60148627,  0.03183409])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.predict(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-27-0837fcf1e999>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-27-0837fcf1e999>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    [1 2]/2\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "[1 2]/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns, data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set,test_set = test_train_split(data,0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
